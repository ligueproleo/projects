{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMViq+sIvUqitiLiLLLuip3",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ligueproleo/Foundation_Trilogy/blob/main/word_embedding_leo.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Desafio 4 - Curso Redes Generativas - Word Embedding"
      ],
      "metadata": {
        "id": "xv1YBwgMEoUX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "\n",
        "# URL do arquivo raw no GitHub\n",
        "url = \"https://raw.githubusercontent.com/ligueproleo/Foundation_Trilogy/main/Isaac_Asimov_Trilogia_Fundacao.txt\"\n",
        "\n",
        "# Requisição para obter o conteúdo do arquivo\n",
        "response = requests.get(url)\n",
        "\n",
        "# Verifica se a requisição foi bem-sucedida (status code 200)\n",
        "if response.status_code == 200:\n",
        "    # O conteúdo do arquivo está em response.text\n",
        "    conteudo_do_arquivo = response.text\n",
        "\n",
        "    # Agora você pode usar 'conteudo_do_arquivo' conforme necessário\n",
        "    # Por exemplo, imprimir as primeiras 1000 caracteres:\n",
        "    print(conteudo_do_arquivo[:5000])\n",
        "else:\n",
        "    print(f\"Erro ao acessar o arquivo. Código de status: {response.status_code}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hSD1nGomEwpE",
        "outputId": "09ea1fdd-605f-4397-c050-21c70b9d8991"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ISAAC ASIMOV\r\n",
            "\r\n",
            "       \r\n",
            "\r\n",
            "\r\n",
            " \r\n",
            " \r\n",
            " \r\n",
            "Funda��o\r\n",
            "Funda��o e Imp�rio\r\n",
            "Segunda Funda��o\r\n",
            "\r\n",
            "\r\n",
            "\r\n",
            "\r\n",
            "\r\n",
            "\r\n",
            "\r\n",
            "Trilogia \r\n",
            "FUNDA��O \r\n",
            "FUNDA��O E IMP�RIO \r\n",
            "SEGUNDA FUNDA��O\r\n",
            "\r\n",
            "\r\n",
            "PREF�CIO\r\n",
            "\r\n",
            "      Uma obra de fic��o implica geralmente em um pouco mais que saber \r\n",
            "escrever bem. O conhecimento cient�fico � desej�vel, mas, acima de tudo, o que \r\n",
            "importa � imagina��o.\r\n",
            "      Isaac Asimov talvez seja o maior pol�grafo de nossa �poca, pelo menos e \r\n",
            "como registra a 115� Edi��o da Enciclop�dia Gal�ctica, e seus trabalhos se \r\n",
            "estendem desde obras de vulgariza��o cientifica, como O Corpo Humano e O \r\n",
            "C�rebro Humano em que um estilo leve e vivo estabelece um estudo completo do \r\n",
            "animal \"Homo Sapiens\", at� os altos v�os de imagina��o em que todo um novo \r\n",
            "Cosmos � constru�do, na trilogia que � atualmente um cl�ssico: Funda��o.\r\n",
            "      Os cr�ticos liter�rios normalmente afetam um total desconhecimento das \r\n",
            "obras de fic��o cientifica, pretendendo com isso afetar uma aus�ncia de conte�do \r\n",
            "art�stico neste g�nero de literatura. Talvez tenham cometido a� mais um engano.\r\n",
            "Entre outras coisas, qualquer manifesta��o atrav�s de qualquer classe de signos \r\n",
            "comporta uma apreens�o e decodifica��o por parte de quem os recebe. A�, � \r\n",
            "evidente, no processo de decodifica��o � que reside a maior ou menor dose de \r\n",
            "efici�ncia do autor, isto �, se digo \"laranja\", duas poss�veis interpreta��es, pelo \r\n",
            "menos, podem ser dadas: o fruto ou a cor. E claro que o sistema de codifica��o \r\n",
            "pode variar, mas sempre � importante e mesmo indispens�vel a presen�a daquele \r\n",
            "que se v� frente ao s�mbolo.\r\n",
            "      Neste caso, temos aqui um universo que se sente subitamente desnudado \r\n",
            "pelos psicohistoriadores, que s�o homens que aplicam a probabilidade a hist�ria. \r\n",
            "V�rios problemas ligados ao conhecimento podem ser colocados a�: em que medida \r\n",
            "um fen�meno hist�rico pode ser alterado por esta ou aquela a��o, que signific�ncia \r\n",
            "pode ter, por exemplo, o choque de um meteorito em termos da hist�ria de um povo? \r\n",
            "Alguns dir�o que nenhuma influ�ncia poder� ter uma circunst�ncia t�o fortuita, a \r\n",
            "menos que chegue a destruir o arsenal, ou mesmo a sede do governo de um pa�s. \r\n",
            "Mas que dizer da pedra negra da Mercaba, a que acorrem milh�es de peregrinos \r\n",
            "todo ano?\r\n",
            "      O universo que aparentemente se mostra t�o concreto e t�o familiar ao \r\n",
            "homem come�a a perder a sua consist�ncia, e isso j� � sobejamente indicado pelas \r\n",
            "obras de Charles Fort. Este �ltimo em seu O Livro dos Danados indica \r\n",
            "acontecimentos naturais ocorridos' que se assemelham a imposs�veis. Asimov \r\n",
            "limita-se a assinalar possibilidades, n�o para um mundo distante e diferente do \r\n",
            "nosso, apenas para um mundo que � o nosso e que n�o se torna distante de si \r\n",
            "mesmo com a expans�o que sofre. Os seres humanos continuam tendo suas \r\n",
            "veleidades e mesquinharias, tudo parece muito normal e concreto.\r\n",
            "      � claro, nem tudo � real e concreto nesse processo, a probabilidade sempre \r\n",
            "lida com uma indu��o, ou melhor, serve de fundamento para esta. Assim, no \r\n",
            "mundo superordenado de Hari Seldon e dos psicohistoriadores, sempre o velho \r\n",
            "problema da indu��o se colocava: que vari�vel n�o seria prevista, que problema \r\n",
            "poderia surgir que viesse a turvar as previs�es de Seldon e sua equipe? Entre as \r\n",
            "v�rias op��es poss�veis, Asimov faz a feliz escolha de um mutante, que tem \r\n",
            "caracter�sticas bastante definidas e que por ser exce��o mexe tamb�m com uma \r\n",
            "exce��o no ser humano: as emo��es.\r\n",
            "      � interessante observar que o lado emocional do homem parece ter sido \r\n",
            "completamente esquecido, nenhum desenvolvimento parece ter revolucionado \r\n",
            "nossas sensa��es e talvez precisamente disso advenha nossa for�a e nossa \r\n",
            "vulnerabilidade.\r\n",
            "      At� que ponto tamb�m a barb�rie pode significar regress�o, na medida em \r\n",
            "que o termo \"barb�rie\" � definido em rela��o a uma determinada forma cultural? \r\n",
            "Assim, a vida b�rbara dos polin�sios fica muitos furos acima da nossa em termos \r\n",
            "de paz e relacionamento. \r\n",
            "\tA tecnologia, esse terr�vel mito endeusado e colocado acima e fora da esfera \r\n",
            "de seu criador, isto �, o homem, gera uma sociedade constitu�da por multiplicidade \r\n",
            "de indiv�duos, isto �, uma sociedade atomizada, em que cada �tomo desconhece a \r\n",
            "exist�ncia de outros desde que a intera��o destes n�o lhe seja necess�ria.\r\n",
            "      Asimov sempre se preocupa com o problema da rela��o entre m�quina e \r\n",
            "homem. Em sua obra j� famosa, Eu, Rob�, apresenta as leis da rob�tica que visam \r\n",
            "preservar o criador da criatura, em outras palavras, impedir que o Homem se \r\n",
            "transforme num novo Frankenstein. Como toda lei est� sujeita a falhas, trata \r\n",
            "cuidadosamente, em muitas de suas obras posteriores, de explorar \r\n",
            "cuidadosamente as poss�veis defici�ncias que esses irm�os eletromec�nicos do \r\n",
            "Homem possam ter e que venham a provocar riscos � sua seguran�a.\r\n",
            "      Em O Grande Sol de Merc�rio temos a a��o de um rob� avariado quase \r\n",
            "destruindo a um ser humano, em Os Rob�s nova an�lise profunda do tema, em O \r\n",
            "Despertar dos Deuses a sua preocupa��o com o \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import urllib.request\n",
        "import re\n",
        "\n",
        "# URL do arquivo raw no GitHub\n",
        "url = \"https://raw.githubusercontent.com/ligueproleo/Foundation_Trilogy/main/Isaac_Asimov_Trilogia_Fundacao.txt\"\n",
        "\n",
        "# read file into list of lines, ignoring errors\n",
        "with urllib.request.urlopen(url) as response:\n",
        "    lines = response.read().decode('utf-8', errors='ignore').split(\"\\n\")\n"
      ],
      "metadata": {
        "id": "fQMsCywwFjsG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#import re (não foi necessário aqui porque já foi feita a importação anteriormente no programa)\n",
        "\n",
        "sentences = []\n",
        "\n",
        "for line in lines:\n",
        "    # Converta a linha para minúsculas para ser case insensitive\n",
        "    line = line.lower()\n",
        "\n",
        "    # Remova pontuações e caracteres especiais, mantendo apenas letras e números\n",
        "    line = re.sub(r'[^a-zA-Z0-9\\s]', '', line)\n",
        "\n",
        "    # Divida a linha em tokens usando espaços em branco como delimitadores\n",
        "    tokens = line.split()\n",
        "\n",
        "    # Somente mantenha linhas com pelo menos um token\n",
        "    if len(tokens) > 0:\n",
        "        sentences.append(tokens)\n"
      ],
      "metadata": {
        "id": "R6ZlPoTJPp1z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Explicações detalhadas sobre esse trecho do código:\n",
        "\n",
        "line = line.lower(): Converte todas as letras da linha para minúsculas. Isso torna a tokenização case-insensitive, tratando palavras em maiúsculas e minúsculas da mesma forma.\n",
        "\n",
        "line = re.sub(r'[^a-zA-Z0-9\\s]', '', line): Remove todas as pontuações e caracteres especiais, mantendo apenas letras e números. A expressão regular [^a-zA-Z0-9\\s] significa \"qualquer caractere que não seja uma letra maiúscula ou minúscula, número ou espaço em branco\". Isso ajuda a manter apenas os caracteres relevantes para a análise textual.\n",
        "\n",
        "tokens = line.split(): Divide a linha em tokens usando espaços em branco como delimitadores. Isso cria uma lista de palavras da linha.\n",
        "\n",
        "if len(tokens) > 0: e sentences.append(tokens): Garante que apenas linhas com pelo menos um token sejam adicionadas à lista sentences. Isso evita a inclusão de linhas em branco ou que consistem apenas de pontuações.\n",
        "\n",
        "Esse código modificado aborda algumas das preocupações mencionadas e deve ser mais flexível e eficaz para o processamento do texto. Certifique-se de ajustar conforme necessário, dependendo dos requisitos específicos do seu projeto."
      ],
      "metadata": {
        "id": "A8rXf9akQEsT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Treinar um Modelo"
      ],
      "metadata": {
        "id": "riw7gViEbdw4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from gensim.models import Word2Vec\n",
        "\n",
        "bard2vec = Word2Vec(\n",
        "         sentences,\n",
        "         min_count=3,   # Ignora palavras que aparecem menos de 3 vezes\n",
        "         vector_size=50,       # Dimensionalidade dos embeddings de palavras\n",
        "         sg=1,        # Usa o método skip-gram (1 para skip-gram, 0 para CBOW)\n",
        "         window=7,      # Janela de contexto para palavras durante o treinamento\n",
        "         epochs=40)       # Número de épocas de treinamento sobre o corpus\n"
      ],
      "metadata": {
        "id": "3Rxg_9KjbhWm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "bard2vec.wv.most_similar('fundacao')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 342
        },
        "id": "bIcYXhVGnWME",
        "outputId": "d4740e50-fa69-4fb3-83b4-4e936294440d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "KeyError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-36-c1bc9a41cb3c>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mbard2vec\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmost_similar\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'fundacao'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/gensim/models/keyedvectors.py\u001b[0m in \u001b[0;36mmost_similar\u001b[0;34m(self, positive, negative, topn, clip_start, clip_end, restrict_vocab, indexer)\u001b[0m\n\u001b[1;32m    839\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    840\u001b[0m         \u001b[0;31m# compute the weighted average of all keys\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 841\u001b[0;31m         \u001b[0mmean\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_mean_vector\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkeys\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpre_normalize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpost_normalize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mignore_missing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    842\u001b[0m         all_keys = [\n\u001b[1;32m    843\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mkey\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mkeys\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_KEY_TYPES\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhas_index_for\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/gensim/models/keyedvectors.py\u001b[0m in \u001b[0;36mget_mean_vector\u001b[0;34m(self, keys, weights, pre_normalize, post_normalize, ignore_missing)\u001b[0m\n\u001b[1;32m    516\u001b[0m                 \u001b[0mtotal_weight\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mabs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweights\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    517\u001b[0m             \u001b[0;32melif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mignore_missing\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 518\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Key '{key}' not present in vocabulary\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    519\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    520\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mtotal_weight\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyError\u001b[0m: \"Key 'fundacao' not present in vocabulary\""
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### O código fornecido usa a biblioteca gensim para treinar um modelo Word2Vec a partir das sentenças processadas anteriormente. O Word2Vec é um algoritmo popular para aprender representações vetoriais de palavras, o que pode ser útil em tarefas de processamento de linguagem natural.\n",
        "\n",
        "Explicações detalhadas:\n",
        "\n",
        "from gensim.models import Word2Vec: Importa a classe Word2Vec da biblioteca Gensim, que é uma biblioteca popular para processamento de linguagem natural.\n",
        "\n",
        "bard2vec = Word2Vec(: Cria uma instância do modelo Word2Vec chamada bard2vec.\n",
        "\n",
        "sentences,: Passa as sentenças processadas como dados de entrada para o modelo.\n",
        "\n",
        "min_count=3,: Ignora palavras que aparecem menos de 3 vezes no corpus. Isso ajuda a remover palavras muito raras que podem não contribuir significativamente para as representações vetoriais.\n",
        "\n",
        "vector_size=50,: Define a dimensionalidade dos embeddings de palavras como 50. Isso determina o número de dimensões nos quais cada palavra será representada.\n",
        "\n",
        "sg=1,: Usa o método skip-gram. O valor 1 indica que o método skip-gram será utilizado, enquanto o valor 0 indicaria o uso do método CBOW (Continuous Bag of Words).\n",
        "\n",
        "window=7,: Define a janela de contexto para palavras durante o treinamento como 7. Isso significa que o modelo levará em consideração 7 palavras à esquerda e à direita de uma palavra alvo ao aprender as representações vetoriais.\n",
        "\n",
        "epochs=40): Define o número de épocas de treinamento sobre o corpus como 40. Uma época é uma passagem completa pelos dados de treinamento.\n",
        "\n",
        "Podemos ainda, ajustar ajustar os parâmetros com base nas características específicas do corpus e das necessidades da aplicação.  É uma questão de tentar alternativas."
      ],
      "metadata": {
        "id": "CB4iA-2cfr7q"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### A seguir criamos uma alternativa para treinar um modelo, mas não achamos interessante porque o fasttext exigia que o arquivo de dados fosse baixado localmente, e nós já havíamos criado um repositório no github e queríamos usa-lo diretamente. Todavia, ele está aí, e funcionando para comparação."
      ],
      "metadata": {
        "id": "kGPtwvOnat3K"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install fasttext\n",
        "import fasttext\n",
        "import urllib.request\n",
        "\n",
        "# Baixa o arquivo de texto localmente\n",
        "url = \"https://raw.githubusercontent.com/ligueproleo/Foundation_Trilogy/main/Isaac_Asimov_Trilogia_Fundacao.txt\"\n",
        "local_filename, headers = urllib.request.urlretrieve(url, filename=\"local_text_file.txt\")\n",
        "\n",
        "# Cria um modelo Word2Vec usando fasttext\n",
        "model = fasttext.train_unsupervised(input=local_filename, model='skipgram', dim=50, epoch=40, minCount=3, ws=7)\n",
        "\n",
        "# Salva o modelo treinado\n",
        "model.save_model('fasttext_skipgram_model.bin')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N6vvfW9bUek7",
        "outputId": "597ae822-3a3f-4cf3-96cd-a83de63453e7"
      },
      "execution_count": null,
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: fasttext in /usr/local/lib/python3.10/dist-packages (0.9.2)\n",
            "Requirement already satisfied: pybind11>=2.2 in /usr/local/lib/python3.10/dist-packages (from fasttext) (2.11.1)\n",
            "Requirement already satisfied: setuptools>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from fasttext) (67.7.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from fasttext) (1.23.5)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "SkNGA79gbTxk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Nesse trecho de código:\n",
        "*   Baixamos o arquivo de texto da URL fornecida usando urllib.request.urlretrieve.\n",
        "*   Utilizamos o nome local do arquivo (local_text_file.txt) como entrada para o método train_unsupervised."
      ],
      "metadata": {
        "id": "5CmsVxVycF9f"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "KDboaHakeCRK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### O comando bard2vec.wv.most_similar('fundacao') realiza uma operação semelhante ao comando anterior, mas procura por palavras semanticamente mais similares à palavra 'fundacao' no modelo Word2Vec treinado (bard2vec). Aqui está uma explicação detalhada:\n",
        "\n",
        "bard2vec: Este é o modelo Word2Vec treinado que contém as representações vetoriais de palavras.\n",
        "\n",
        "wv: Este é o atributo do modelo Word2Vec que representa o Word Vectors (vetores de palavras).\n",
        "\n",
        "most_similar('fundacao'): Este método encontra as palavras mais similares à palavra fornecida como argumento ('fundacao' neste caso) com base nas representações vetoriais aprendidas durante o treinamento do modelo. O resultado é uma lista de tuplas onde cada tupla contém uma palavra similar e uma pontuação de similaridade.\n",
        "\n",
        "Assim, bard2vec.wv.most_similar('fundacao') retorna as palavras semanticamente mais similares à palavra 'fundacao' de acordo com o modelo Word2Vec treinado. Essas palavras são determinadas pela proximidade de vetores no espaço vetorial de palavras, refletindo a coocorrência e similaridade contextual durante o treinamento do modelo."
      ],
      "metadata": {
        "id": "EjEC4Dfrkp2y"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Encontrar palavras similares semânticamente"
      ],
      "metadata": {
        "id": "hzVF70zMmYiX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Carrega o modelo treinado\n",
        "model = fasttext.load_model('fasttext_skipgram_model.bin')\n",
        "\n",
        "# Encontra palavras mais similares\n",
        "similar_words = model.get_nearest_neighbors('fundacao', k=5)\n",
        "\n",
        "# Imprime os resultados\n",
        "for word, score in similar_words:\n",
        "    print(f'{word}: {score}')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CM4Y8t3ZmYLm",
        "outputId": "5d2b7c03-c90d-4b2b-bce4-eabe1bf60eff"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Warning : `load_model` does not return WordVectorModel or SupervisedModel any more, but a `FastText` object which is very similar.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.8313055038452148: fundar\n",
            "0.666930079460144: fundamentais\n",
            "0.662959635257721: que\n",
            "0.6624922156333923: queriam\n",
            "0.6348617672920227: aquilo?\n"
          ]
        }
      ]
    }
  ]
}